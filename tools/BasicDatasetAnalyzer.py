import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from collections import defaultdict
from datetime import datetime
from typing import List, Dict, Tuple


class BasicDatasetAnalyzer:
    """
    A class to perform basic analysis of a dataset of publications and generate descriptive summaries using an LLM.

    Attributes:
        llm (ChatOpenAI): The language model used to generate descriptions.
        dataset (List[Dict]): The dataset containing publication records.
    """

    def __init__(self, llm: ChatOpenAI):
        """
        Initializes the DatasetAnalyzer with a language model and dataset.

        Args:
            llm (ChatOpenAI): An instance of the ChatOpenAI language model.
            dataset (List[Dict]): A list of publication records, each represented as a dictionary.
        """
        self.llm = llm

    def analyze_dataset(self) -> Dict:
        """
        Performs basic analysis on the dataset, including total publications, date range, and publications per year.

        Returns:
            Dict: A dictionary containing the analysis results.
        """
        total_publications = len(self.dataset)
        publication_years = []

        for record in self.dataset:
            pub_date_str = record.get('PublicationDate', '')
            try:
                # Attempt to parse the publication date
                pub_date = datetime.strptime(pub_date_str, '%Y-%b')  # Example format: '2016-Jun'
                publication_years.append(pub_date.year)
            except ValueError:
                try:
                    pub_date = datetime.strptime(pub_date_str, '%Y-%m-%d')  # Example format: '2016-02-01'
                    publication_years.append(pub_date.year)
                except ValueError:
                    # If date parsing fails, skip the record or handle accordingly
                    continue

        if not publication_years:
            date_range = "Unknown"
            publications_over_time = {}
        else:
            start_year = min(publication_years)
            end_year = max(publication_years)
            date_range = f"{start_year}-{end_year}"

            # Calculate publications per year
            publications_over_time = defaultdict(int)
            for year in publication_years:
                publications_over_time[year] += 1

            # Convert defaultdict to regular dict and sort by year
            publications_over_time = dict(sorted(publications_over_time.items()))

        analysis = {
            "Total Publications": total_publications,
            "Date Range": date_range,
            "Publications Over Time": publications_over_time
        }

        return analysis

    def describe_analysis(self, analysis: Dict) -> str:
        """
        Uses the language model to generate a descriptive summary of the dataset analysis.

        Args:
            analysis (Dict): The analysis results containing total publications, date range, and publications per year.

        Returns:
            str: A descriptive summary generated by the LLM.
        """
        prompt = (
            f"Provide a concise summary based on the following dataset analysis:\n\n"
            f"Total Publications: {analysis['Total Publications']}\n"
            f"Date Range of Publications: {analysis['Date Range']}\n"
            f"Number of Publications Over Time:\n"
        )

        for year, count in analysis['Publications Over Time'].items():
            prompt += f"  {year}: {count} publications\n"

        prompt += "\nDescribe the dataset characteristics and any observable trends."

        response = self.llm.generate(prompt)
        return response

    def __call__(self, dataset: List[Dict]) -> Tuple[Dict, str]:
        """
        Executes the dataset analysis and generates a descriptive summary.

        Returns:
            Tuple[Dict, str]: A tuple containing the analysis dictionary and the descriptive summary.
        """
        self.dataset = dataset
        analysis = self.analyze_dataset()
        print("Analysis", analysis)
        description = self.describe_analysis(analysis)
        return analysis, description
    

# Example Usage
if __name__ == "__main__":
    # Load environment variables from .env file
    load_dotenv()
    openai_api_key = os.getenv("OPENAI_API_KEY")

    def create_llm(llm_name: str, temperature: float = 0.2) -> ChatOpenAI:
        """
        Creates an instance of the ChatOpenAI language model.

        Args:
            llm_name (str): The name of the OpenAI model to use.
            temperature (float, optional): Sampling temperature. Defaults to 0.2.

        Returns:
            ChatOpenAI: An instance of the ChatOpenAI model.
        """
        return ChatOpenAI(
            model_name=llm_name,
            openai_api_key=openai_api_key,
            temperature=temperature
        )

    # Initialize LLM instances
    gpt_4 = create_llm("gpt-4")

    # Example dataset
    dataset = [
        {
            'PMID': '26690495',
            'Title': 'Ultra-fast magnetic resonance encephalography of physiological brain activity - Glymphatic pulsation mechanisms?',
            'Abstract': "The theory on the glymphatic convection mechanism of cerebrospinal fluid holds that cardiac pulsations...",
            'Authors': ['Vesa Kiviniemi', 'Xindi Wang', 'Vesa Korhonen', 'Tuija Keinänen', 'Timo Tuovinen', 'Joonas Autio', 'Pierre LeVan', 'Shella Keilholz', 'Yu-Feng Zang', 'Jürgen Hennig', 'Maiken Nedergaard'],
            'PublicationDate': '2016-Jun',
            'Keywords': ['Resting state', 'blood oxygen level dependent', 'cardiorespiratory', 'glymphatics', 'magnetic resonance encephalography'],
            'Journal': 'Journal of cerebral blood flow and metabolism',
            'Copyright': '© The Author(s) 2015.',
            'Abstract Normalized': 'theori glymphat convect mechan cerebrospin fluid hold cardiac pulsat part pump...'
        },
        {
            'PMID': '26688469',
            'Title': 'Rapid intranasal delivery of chloramphenicol acetyltransferase in the active form to different brain regions as a model for enzyme therapy in the CNS.',
            'Abstract': 'The blood brain barrier (BBB) is critical for maintaining central nervous system (CNS) homeostasis by restricting entry of potentially toxic substances...',
            'Authors': ['Abhilash P Appu', 'Peethambaran Arun', 'Jishnu K S Krishnan', 'John R Moffett', 'Aryan M A Namboodiri'],
            'PublicationDate': '2016-Feb-01',
            'Keywords': ['Bioavailability', 'Catalytic bioscavenger', 'Enzyme deficiency diseases', 'Glymphatic system', 'Organophosphate chemical threat agents'],
            'Journal': 'Journal of neuroscience methods',
            'BACKGROUND': 'The blood brain barrier (BBB) is critical for maintaining central nervous system (CNS) homeostasis...',
            'NEW METHOD': 'The aim of this work is to provide a sensitive model system for analyzing the rapid delivery of active enzymes...',
            'RESULTS': 'We tested intranasal delivery of chloramphenicol acetyltransferase (CAT)...',
            'COMPARISON WITH EXISTING METHOD (S)': 'Intranasal administration of active enzymes in conjunction with MMP-9 to the CNS is both rapid and effective.',
            'CONCLUSION': 'The present results suggest that intranasal enzyme therapy is a promising method...',
            'Abstract Normalized': 'blood brain barrier bbb critic maintain central nervou system cn homeostasi restrict entri potenti toxic substanc...'
        }
    ]

    # Initialize the DatasetAnalyzer
    analyzer = DatasetAnalyzer(llm=gpt_4, dataset=dataset)

    # Run the analysis
    analysis_results, description = analyzer.run_analysis()

    # Output the results
    print("Analysis Results:")
    print(analysis_results)
    print("\nDescriptive Summary:")
    print(description)
